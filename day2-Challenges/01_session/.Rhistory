p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts),
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"\nout of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0, vjust=5) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
?annotate
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts)-0.10,
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"\nout of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts)-2,
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"\nout of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts)-10,
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"\nout of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts)-20,
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"\nout of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts),
label = paste("Experiments with at least\none significant result:", experiments_with_sig,
"out of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
simulate_p_hacking <- function(n_experiments = 100, n_tests = 10, sample_size = 30, true_effect = 0) {
# Matrix to store p-values for each experiment and test
p_values_matrix <- matrix(nrow = n_experiments, ncol = n_tests)
for (i in 1:n_experiments) {
for (j in 1:n_tests) {
# Generate two groups of data
group1 <- rnorm(sample_size, mean = 0, sd = 1)
group2 <- rnorm(sample_size, mean = true_effect, sd = 1)
# Perform t-test
test_result <- t.test(group1, group2)
p_values_matrix[i,j] <- test_result$p.value
}
}
return(p_values_matrix)
}
# Run simulation
n_experiments <- 100
n_tests <- 5
p_values_matrix <- simulate_p_hacking(n_experiments = n_experiments, n_tests = n_tests)
# Calculate number of experiments with at least one significant result
experiments_with_sig <- sum(apply(p_values_matrix, 1, function(x) any(x < 0.05)))
# Create data for plotting
p_values_long <- data.frame(p_value = as.vector(p_values_matrix))
# Visualize the distribution of p-values
ggplot(p_values_long, aes(x = p_value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
geom_vline(xintercept = 0.05, color = "red", linetype = "dashed") +
annotate("text", x = 0.1, y = max(hist(p_values_long$p_value, breaks = 30, plot = FALSE)$counts),
label = paste("Experiments with at least one significant result:", experiments_with_sig,
"out of", n_experiments, "experiments\n(",
round(100 * experiments_with_sig/n_experiments, 1), "%)"),
hjust = 0) +
labs(title = "Distribution of P-Values from Multiple Experiments",
subtitle = paste(n_tests, "tests per experiment"),
x = "P-Value",
y = "Frequency")
setwd("C:/Users/david/Documents/GitHub/ReproScience/day2-Challenges/01_session")
# we are loading the data-set, it takes the form of an .RData file, saved with save(), something
# that can be loaded straight away into R, after loading you will see data.frame object in the  Environment window.
load(file='./data/hurricane.RData') # this is where it helps to check the name of the data that was just loaded in the Environment window
# Display the first few rows of the dataset
head(hurricane_data)  # Check the structure of the dataset
str(hurricane_data)
# some options for chunks: we ask for it to produce outputs, no messages or warnings
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = TRUE)
# You will bbe asksed whether you want to install from source, say yes
if (!require("specr"))
install.packages("specr")
if (!require("tidyverse"))
install.packages("tidyverse")
if (!require("ggplot2"))
install.packages("ggplot2")
library(tidyverse)
library(specr)
library(future)
results <- specr(specs) # Summarize results summary(results)
# some options for chunks: we ask for it to produce outputs, no messages or warnings
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = TRUE)
# You will bbe asksed whether you want to install from source, say yes
if (!require("specr"))
install.packages("specr")
if (!require("tidyverse"))
install.packages("tidyverse")
if (!require("ggplot2"))
install.packages("ggplot2")
library(tidyverse)
library(specr)
results <- specr(specs) # Summarize results summary(results)
specs <- setup(data = hurricane_data, # our dataset
x = c("masfem", "masfem:dam", "masfem:zpressure"), # we are entering options for independent variables, those are our main variables of interest
y = c("death","dam"), # options for dependent variables, we could predict damage amount instead of deaths
control = c("masfem:dam", "masfem:zpressure"), # options for control variables, that is other predictors in our model
model = c("lm","glm"), # options for models
simplify = TRUE)
# we are loading the data-set, it takes the form of an .RData file, saved with save(), something
# that can be loaded straight away into R, after loading you will see data.frame object in the  Environment window.
load(file='./data/hurricane.RData') # this is where it helps to check the name of the data that was just loaded in the Environment window
# Display the first few rows of the dataset
head(hurricane_data)  # Check the structure of the dataset
str(hurricane_data)
# We are going to focus on the following variables in the Hurricane dataset
# death: number of deaths
# masfem: whether the name is seen masculine or feminine (rating scale)
# dam: damage
# zpressure: z-transformed atmospheric pressure
# This is more or less the original analysis in the Paper, showing a significant effect of name "feminity"
# We apply a general linear mode of a certain type (poisson)
# Poisson models are common for count data with a certain type of distribution (e.g., number of deaths, number of neurons action potentials)
fit <- glm(death ~ masfem * dam + masfem * zpressure, data = hurricane_data, family = "poisson")
# As odd as it sounds, we see a significant effect of the femininity of the hurricane (masfem)
summary(fit)
specs <- setup(data = hurricane_data, # our dataset
x = c("masfem", "masfem:dam", "masfem:zpressure"), # we are entering options for independent variables, those are our main variables of interest
y = c("death","dam"), # options for dependent variables, we could predict damage amount instead of deaths
control = c("masfem:dam", "masfem:zpressure"), # options for control variables, that is other predictors in our model
model = c("lm","glm"), # options for models
simplify = TRUE)
results <- specr(specs) # Summarize results summary(results)
results
View(results)
View(results)
results$model
results$data
# Function to calculate power for a given sample size
# we are going to build on the previous chunk function sim_alternative fun that picks random samples
# under the independent groups scenario
# note the function sets defaults for the parameters, this could be changed dynamically as well
# sims = number of simulations of one test / experiment
calculate_power_fun <- function(n, mean1 = 10, mean2 = 15, sd = 5, sims = 1000) {
p_values <- replicate(sims, sim_alternative_fun(n, mean1, mean2, sd))
return(mean(p_values < 0.05))
}
# Sample sizes to test
sample_sizes <- ______
# Calculate power for each sample size
power_values <- sapply(sample_sizes, calculate_power_fun)
# Create a data frame for plotting
power_data <- data.frame(SampleSize = sample_sizes, Power = power_values)
# Plot power vs. sample size
ggplot(power_data, aes(x = SampleSize, y = Power)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Power vs. Sample Size", x = "Sample Size", y = "Power") +
theme_minimal()
# Function to simulate one experiment under the null hypothesis
# We define two groups, independent of each other
# we run a t-test (base R) assuming variances are equal and return the p-value
sim_null_fun <- function(n = 10, mean = 10, sd = 5) {
group1 <- rnorm(n, mean, sd)
group2 <- rnorm(n, mean, sd)
result <- t.test(group1, group2, var.equal = TRUE)
return(result$p.value)
}
# You can replicate the experiment a number of times (that is run the function) with replicate()
# Simulate 1000 experiments with replicate()
number_of_replications <- 1000
null_p_values <- replicate(number_of_replications, sim_null_fun())
# Let's plot the distribution of p-values
hist(null_p_values,
breaks = 30,
col = "skyblue",
main = "Null Distribution of P-Values",
xlab = "P-Value")
abline(v = 0.05, col = "red", lwd = 2, lty = 2)
# Calculate the proportion of p-values below 0.05
sign_p_vals<-mean(null_p_values < 0.05)
print(sign_p_vals)
# Function to simulate one experiment under the alternative hypothesis
sim_alternative_fun <- function(n = 20, mean1 = 10, mean2 = 12.5, sd = 5) {
group1 <- rnorm(n, mean1, sd)
group2 <- rnorm(n, mean2, sd)
result <- t.test(group1, group2, var.equal = TRUE)
return(result$p.value)
}
# Simulate 1000 experiments to see the distribution of p-values for an effect that exists
alt_p_values <- replicate(1000, sim_alternative_fun())
# Plot the distribution of p-values
hist(alt_p_values,
breaks = 30,
col = "lightgreen",
main = "Distribution of P-Values given an existing effect",
xlab = "P-Value")
abline(v = 0.05, col = "red", lwd = 2, lty = 2)
print(mean(alt_p_values < 0.05))
# Function to calculate power for a given sample size
# we are going to build on the previous chunk function sim_alternative fun that picks random samples
# under the independent groups scenario
# note the function sets defaults for the parameters, this could be changed dynamically as well
# sims = number of simulations of one test / experiment
calculate_power_fun <- function(n, mean1 = 10, mean2 = 15, sd = 5, sims = 1000) {
p_values <- replicate(sims, sim_alternative_fun(n, mean1, mean2, sd))
return(mean(p_values < 0.05))
}
# Sample sizes to test
sample_sizes <- ______
# Calculate power for each sample size
power_values <- sapply(sample_sizes, calculate_power_fun)
# Create a data frame for plotting
power_data <- data.frame(SampleSize = sample_sizes, Power = power_values)
# Plot power vs. sample size
ggplot(power_data, aes(x = SampleSize, y = Power)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Power vs. Sample Size", x = "Sample Size", y = "Power") +
theme_minimal()
# Function to calculate power for a given sample size
# we are going to build on the previous chunk function sim_alternative fun that picks random samples
# under the independent groups scenario
# note the function sets defaults for the parameters, this could be changed dynamically as well
# sims = number of simulations of one test / experiment
calculate_power_fun <- function(n, mean1 = 10, mean2 = 15, sd = 5, sims = 1000) {
p_values <- replicate(sims, sim_alternative_fun(n, mean1, mean2, sd))
return(mean(p_values < 0.05))
}
# Sample sizes to test
sample_sizes <- c(10,20,30)
# Calculate power for each sample size
power_values <- sapply(sample_sizes, calculate_power_fun)
# Create a data frame for plotting
power_data <- data.frame(SampleSize = sample_sizes, Power = power_values)
# Plot power vs. sample size
ggplot(power_data, aes(x = SampleSize, y = Power)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Power vs. Sample Size", x = "Sample Size", y = "Power") +
theme_minimal()
# Calculate difference in means and CI
mean_diff <- mean2 - mean1
se_diff <- sqrt(se1^2 + se2^2)
ci_diff <- c(mean_diff - 1.96 * se_diff, mean_diff + 1.96 * se_diff)
# Plot the effect size and CI
plot(1, mean_diff, ylim = c(ci_diff[1] - 5, ci_diff[2] + 5), pch = 19,
xlab = "Effect Size", ylab = "Difference in Means",
main = "Confidence Interval for Effect Size")
arrows(1, ci_diff[1], 1, ci_diff[2], angle = 90, code = 3, length = 0.1, col = "blue")
# Set seed for reproducibility
set.seed(42)
# Simulate data
n <- 30  # Sample size
mu <- 100  # True mean
sigma <- 15  # Standard deviation
# Generate random sample
data <- rnorm(n, mean = mu, sd = sigma)
# Calculate mean and 95% CI
mean_sample <- mean(data)
se <- sd(data) / sqrt(n)
ci_lower <- mean_sample - 1.96 * se
ci_upper <- mean_sample + 1.96 * se
# Print results
cat("Sample Mean:", round(mean_sample, 2), "\n")
cat("95% CI: [", round(ci_lower, 2), ",", round(ci_upper, 2), "]\n")
# Simulate multiple samples and their CIs
n_samples <- 50
n <- 30
mu <- 100
sigma <- 15
# Generate samples and calculate CIs
results <- replicate(n_samples, {
data <- rnorm(n, mean = mu, sd = sigma)
mean_sample <- mean(data)
se <- sd(data) / sqrt(n)
ci_lower <- mean_sample - 1.96 * se
ci_upper <- mean_sample + 1.96 * se
c(mean = mean_sample, ci_lower = ci_lower, ci_upper = ci_upper)
})
# Convert to data frame
results_df <- as.data.frame(t(results))
# Plot the CIs
library(ggplot2)
ggplot(results_df, aes(x = 1:n_samples, y = mean)) +
geom_point() +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
labs(title = "Confidence Intervals Across Samples",
x = "Sample Number", y = "Mean Estimate") +
theme_minimal()
# Function to calculate CI width for different sample sizes
ci_width <- function(n, mu = 100, sigma = 15) {
data <- rnorm(n, mean = mu, sd = sigma)
se <- sd(data) / sqrt(n)
ci_width <- 2 * 1.96 * se  # Width of 95% CI
return(ci_width)
}
# Sample sizes to test
sample_sizes <- seq(10, 200, by = 10)
# Calculate CI widths
ci_widths <- sapply(sample_sizes, ci_width)
# Plot CI width vs. sample size
plot(sample_sizes, ci_widths, type = "b", col = "blue",
xlab = "Sample Size", ylab = "CI Width",
main = "Effect of Sample Size on CI Width")
# Function to calculate required sample size for a given CI width
required_sample_size_fun <- function(desired_width, sigma = 15) {
n <- (2 * 1.96 * sigma / desired_width)^2
return(ceiling(n))  # Round up to the nearest whole number
}
# Desired CI width
desired_width <- 5
# Calculate required sample size
n_required <- required_sample_size_fun(desired_width)
cat("Required Sample Size for CI Width of", desired_width, ":", n_required, "\n")
# Simulate data for two groups
n <- 30
mu1 <- 100
mu2 <- 110
sigma <- 15
group1 <- rnorm(n, mean = mu1, sd = sigma)
group2 <- rnorm(n, mean = mu2, sd = sigma)
# Calculate means and CIs
mean1 <- mean(group1)
mean2 <- mean(group2)
se1 <- sd(group1) / sqrt(n)
se2 <- sd(group2) / sqrt(n)
ci1 <- c(mean1 - 1.96 * se1, mean1 + 1.96 * se1)
ci2 <- c(mean2 - 1.96 * se2, mean2 + 1.96 * se2)
# Print results
cat("Group 1: Mean =", round(mean1, 2), ", 95% CI =", round(ci1, 2), "\n")
cat("Group 2: Mean =", round(mean2, 2), ", 95% CI =", round(ci2, 2), "\n")
# Calculate difference in means and CI
mean_diff <- mean2 - mean1
se_diff <- sqrt(se1^2 + se2^2)
ci_diff <- c(mean_diff - 1.96 * se_diff, mean_diff + 1.96 * se_diff)
# Plot the effect size and CI
plot(1, mean_diff, ylim = c(ci_diff[1] - 5, ci_diff[2] + 5), pch = 19,
xlab = "Effect Size", ylab = "Difference in Means",
main = "Confidence Interval for Effect Size")
arrows(1, ci_diff[1], 1, ci_diff[2], angle = 90, code = 3, length = 0.1, col = "blue")
?vembedr
install.packages("vembeder")
library(vembeder)
library(vembedr)
install.packages("vembedr")
# install.packages("vembedr")
library("vembedr")
embed_url("https://www.youtube.com/watch?v=BD_n6ju9iRA")
# install.packages("vembedr")
library("vembedr")
embed_url("https://www.youtube.com/watch?v=BD_n6ju9iRA")
